<h1>绪论</h1>
<h2>强化学习的历史</h2><br>
<strong>标准强化学习</strong>：设计特征，训练函数采取动作<br>
<strong>深度强化学习</strong>：智能体游戏--动作的端到端训练(end-to-end training)的过程，用神经网络来拟合价值函数或策略网络，省去特征工程
<h2>强化学习与监督学习</h2><br>
在监督学习中：<br>
1.输入的数据没有关联((设空间中样本独立同分布（iid))<br>
2.学习器需要有正确的标签<br>
在强化学习中：<br>
1.数据是相关的时间序列，不满足独立同分布<br>
2.没有非常强的监督者，只有<strong>奖励信号(reward signal)</strong>,无法获得立刻的反馈，面临<strong>延迟反馈</strong>问题</br>


<h2>预演，轨迹，实验，奖励，序列决策</h2>
在强化学习中，智能体进行的一场游戏叫做<strong>回合(episode)</strong>或者<strong>试验(trial)</strong>,对从当前帧进行采样并生成很多局游戏得到的一系列观测被称为<strong>预演（rollot）</strong>，每一个观测可以看做一个<strong>轨迹(trajectory)</strong>,即状态和动作的序列
